{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df34fc34",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "\n",
    "The KLR model is given as \\\n",
    "$$ P(y_i = j) = \\frac{e^{\\bf{w_j}^T \\bf{\\phi}(\\bf{x}_i)}}{\\sum_{l=1}^{k} e^{\\bf{w_l}^T \\bf{\\phi}(\\bf{x}_i)}}, \\quad j = 1, \\cdots, K $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72ec36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## The gradient descent algorithm for the KLR model\n",
    "##########################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# print(X, y)\n",
    "\n",
    "# Data preprocessing for standardized features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X) ## Reference: Oluwagbemisola Oladepo\n",
    "\n",
    "# Define the probability p(y_i = j) = p(x_i)\n",
    "def softmax_p(X, w):\n",
    "    z1 = np.exp(np.dot(X, w))\n",
    "    z2 = np.sum(z1, axis = 1, keepdims = True)\n",
    "    return z1 / z2\n",
    "\n",
    "def characteristic_f(y):\n",
    "    char = np.zeros((n, k))\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            if y[i] == j:\n",
    "                char[i][j] = 1\n",
    "    return char ## Reference: Olivia Brubaker  \n",
    "\n",
    "# Define and implementthe gradient of the given KLR's Cross Entropy function\n",
    "def gradient_descent(X, y, gamma, num_iters):\n",
    "    m = X.shape\n",
    "    n = X.shape\n",
    "    k = len(set(y))\n",
    "    w = np.zeros((n, k))\n",
    "    for i in range(num_iters):\n",
    "        h = softmax_p(X, w)\n",
    "        grad = np.zeros((n, k))\n",
    "        for j in range(k):\n",
    "            grad[:, j] = (1 / m) * (h[:, j] - characteristic_f(y)). dot(X)\n",
    "            w = w - gamma * grad\n",
    "    return w\n",
    "\n",
    "# Define the feature map\n",
    "def x_phi(X, degree = 2):\n",
    "    poly = PolynomialFeatures(degree = 2, interaction_only = False, include_bias = True)\n",
    "    return poly.fit_transform(X)\n",
    "\n",
    "# Set the step size and number of iterations\n",
    "gamma = 0.01\n",
    "num_iters2 = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8311b",
   "metadata": {},
   "source": [
    "##### I will be using kernels 3, 4, 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15e9f8b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m X4_grad \u001b[38;5;241m=\u001b[39m x_phi(X, degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      9\u001b[0m X5_grad \u001b[38;5;241m=\u001b[39m x_phi(X, degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m w3_grad \u001b[38;5;241m=\u001b[39m gradient_descent(X3_grad, y, gamma, num_iters2)\n\u001b[0;32m     12\u001b[0m w4_grad \u001b[38;5;241m=\u001b[39m gradient_descent(X4_grad, y, gamma, num_iters2)\n\u001b[0;32m     13\u001b[0m w5_grad \u001b[38;5;241m=\u001b[39m gradient_descent(X5_grad, y, gamma, num_iters2)\n",
      "Cell \u001b[1;32mIn[76], line 34\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, gamma, num_iters)\u001b[0m\n\u001b[0;32m     32\u001b[0m n \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     33\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(y))\n\u001b[1;32m---> 34\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n, k))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[0;32m     36\u001b[0m     h \u001b[38;5;241m=\u001b[39m softmax_p(X, w)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "## Kernel (poly_degree = 3)\n",
    "#################################\n",
    "\n",
    "#################################\n",
    "## Gradient Descent Method\n",
    "X3_grad = x_phi(X, degree = 3)\n",
    "X4_grad = x_phi(X, degree = 4)\n",
    "X5_grad = x_phi(X, degree = 5)\n",
    "\n",
    "w3_grad = gradient_descent(X3_grad, y, gamma, num_iters2)\n",
    "w4_grad = gradient_descent(X4_grad, y, gamma, num_iters2)\n",
    "w5_grad = gradient_descent(X5_grad, y, gamma, num_iters2)\n",
    "\n",
    "# I got stuck at this point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
